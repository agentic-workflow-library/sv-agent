{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV-Agent Chat Interface Demo\n",
    "\n",
    "This notebook demonstrates the interactive chat capabilities of sv-agent for structural variant analysis using GATK-SV.\n",
    "\n",
    "## Overview\n",
    "\n",
    "sv-agent provides:\n",
    "- **CWL workflow execution** for running GATK-SV analysis\n",
    "- **WDL to CWL conversion** for GATK-SV workflows\n",
    "- **Expert guidance** on structural variant analysis\n",
    "- **Interactive chat** with optional LLM enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and initialize sv-agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from sv_agent import SVAgent\n",
    "from sv_agent.chat import SVAgentChat\n",
    "from sv_agent.llm import OllamaProvider, detect_available_provider\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent\n",
    "agent = SVAgent()\n",
    "print(\"SV-Agent initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Chat Interface\n",
    "\n",
    "Let's start with the rule-based chat system that works without any LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chat with rule-based system (no LLM required)\n",
    "chat_rules = SVAgentChat(agent, llm_provider=\"none\")\n",
    "print(\"Chat initialized with rule-based system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Understanding sv-agent's capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about capabilities\n",
    "response = chat_rules.chat(\"What can you do?\")\n",
    "print(\"Q: What can you do?\")\n",
    "print(\"\\nA:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Running CWL workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about running workflows\n",
    "response = chat_rules.chat(\"How do I run GATK-SV analysis?\")\n",
    "print(\"Q: How do I run GATK-SV analysis?\")\n",
    "print(\"\\nA:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Module-specific information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about specific modules\n",
    "response = chat_rules.chat(\"Explain Module00a\")\n",
    "print(\"Q: Explain Module00a\")\n",
    "print(\"\\nA:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LLM-Enhanced Chat (with Ollama/Gemma)\n",
    "\n",
    "If you have Ollama installed with Gemma, the chat interface provides more natural conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Ollama is available\n",
    "ollama = OllamaProvider(model=\"gemma:2b\")\n",
    "if ollama.is_available():\n",
    "    print(\"✅ Ollama is available\")\n",
    "    models = ollama.list_models()\n",
    "    print(f\"Available models: {models}\")\n",
    "    \n",
    "    # Create LLM-enhanced chat\n",
    "    chat_llm = SVAgentChat(agent, llm_provider=ollama)\n",
    "    print(\"\\nChat initialized with Gemma LLM\")\n",
    "else:\n",
    "    print(\"❌ Ollama not available - using rule-based system\")\n",
    "    chat_llm = chat_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Natural language questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a complex question\n",
    "question = \"I have 100 samples from families with autism. What's the best way to run sv-agent for this cohort?\"\n",
    "response = chat_llm.chat(question)\n",
    "print(f\"Q: {question}\")\n",
    "print(f\"\\nA: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Best Practices and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about coverage requirements\n",
    "response = chat_rules.chat(\"What coverage do I need for reliable SV detection?\")\n",
    "print(\"Q: What coverage do I need for reliable SV detection?\")\n",
    "print(\"\\nA:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Troubleshooting Common Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about troubleshooting\n",
    "response = chat_rules.chat(\"I'm getting very few SV calls. What should I check?\")\n",
    "print(\"Q: I'm getting very few SV calls. What should I check?\")\n",
    "print(\"\\nA:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Workflow Conversion Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about conversion\n",
    "response = chat_rules.chat(\"How do I convert Module00a to CWL?\")\n",
    "print(\"Q: How do I convert Module00a to CWL?\")\n",
    "print(\"\\nA:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical Workflow Execution\n",
    "\n",
    "Let's see how to actually use sv-agent to run analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample input configuration\n",
    "sample_inputs = {\n",
    "    \"bam_file\": {\n",
    "        \"class\": \"File\",\n",
    "        \"path\": \"/data/samples/NA12878.bam\",\n",
    "        \"secondaryFiles\": [\n",
    "            {\"class\": \"File\", \"path\": \"/data/samples/NA12878.bam.bai\"}\n",
    "        ]\n",
    "    },\n",
    "    \"reference\": {\n",
    "        \"class\": \"File\",\n",
    "        \"path\": \"/data/reference/hg38.fa\",\n",
    "        \"secondaryFiles\": [\n",
    "            {\"class\": \"File\", \"path\": \"/data/reference/hg38.fa.fai\"}\n",
    "        ]\n",
    "    },\n",
    "    \"sample_id\": \"NA12878\",\n",
    "    \"sex\": \"female\"\n",
    "}\n",
    "\n",
    "print(\"Sample input configuration:\")\n",
    "print(json.dumps(sample_inputs, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about running with this configuration\n",
    "response = chat_rules.chat(\"I have a BAM file and reference. What's the complete command to run Module00a?\")\n",
    "print(\"Q: I have a BAM file and reference. What's the complete command to run Module00a?\")\n",
    "print(\"\\nA:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Processing Guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about batch processing\n",
    "questions = [\n",
    "    \"How many samples should I include in a batch?\",\n",
    "    \"Can I mix different sequencing platforms?\",\n",
    "    \"How do I handle family samples?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"Q: {q}\")\n",
    "    response = chat_rules.chat(q)\n",
    "    print(f\"A: {response[:300]}...\\n\")\n",
    "    print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Understanding SV Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about different SV types\n",
    "sv_types = [\"DEL\", \"DUP\", \"INV\", \"INS\", \"BND\"]\n",
    "\n",
    "for sv_type in sv_types:\n",
    "    response = chat_rules.chat(f\"What is a {sv_type}?\")\n",
    "    print(f\"Q: What is a {sv_type}?\")\n",
    "    print(f\"A: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance and Resource Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about computational requirements\n",
    "response = chat_rules.chat(\"What computational resources do I need for 500 samples?\")\n",
    "print(\"Q: What computational resources do I need for 500 samples?\")\n",
    "print(\"\\nA:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Session Example\n",
    "\n",
    "Here's how you might use the chat interface interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate an interactive session\n",
    "conversation = [\n",
    "    \"I'm new to structural variant analysis. Where should I start?\",\n",
    "    \"I have 50 whole genome samples at 30x coverage. Is that enough?\",\n",
    "    \"Should I run all modules at once or one by one?\",\n",
    "    \"How long will the analysis take?\",\n",
    "    \"What output files will I get?\"\n",
    "]\n",
    "\n",
    "print(\"=== Interactive SV-Agent Session ===\")\n",
    "print()\n",
    "\n",
    "for i, question in enumerate(conversation, 1):\n",
    "    print(f\"User: {question}\")\n",
    "    response = chat_rules.chat(question)\n",
    "    print(f\"\\nSV-Agent: {response[:400]}...\" if len(response) > 400 else f\"\\nSV-Agent: {response}\")\n",
    "    print(\"\\n\" + \"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Basic chat interface** - Works without any LLM\n",
    "2. **LLM-enhanced chat** - Natural conversations with Ollama/Gemma\n",
    "3. **Capability queries** - Understanding what sv-agent can do\n",
    "4. **Workflow execution** - Running CWL workflows for SV analysis\n",
    "5. **Module information** - Details about GATK-SV modules\n",
    "6. **Best practices** - Coverage, batch size, sample selection\n",
    "7. **Troubleshooting** - Common issues and solutions\n",
    "8. **Resource planning** - Computational requirements\n",
    "\n",
    "### Key Commands\n",
    "\n",
    "- **Convert WDL to CWL**: `sv-agent convert -o output_dir -m ModuleName`\n",
    "- **Run CWL workflow**: `sv-agent run workflow.cwl inputs.yaml`\n",
    "- **Interactive chat**: `sv-agent chat`\n",
    "- **Single question**: `sv-agent ask \"your question\"`\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Convert your GATK-SV WDL workflows to CWL\n",
    "2. Prepare input YAML files for your samples\n",
    "3. Run the analysis with sv-agent\n",
    "4. Use the chat interface for guidance along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a final summary of available modules\n",
    "from sv_agent.knowledge import SVKnowledgeBase\n",
    "\n",
    "kb = SVKnowledgeBase()\n",
    "print(\"Available GATK-SV Modules:\")\n",
    "print(\"=\" * 50)\n",
    "for module_id, info in kb.modules.items():\n",
    "    print(f\"{module_id}: {info['name']} - {info['purpose']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}